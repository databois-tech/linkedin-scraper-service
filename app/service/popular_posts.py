from ..util.random_session_picker import fetch_random_session
from ..util.data_cleaner import data_filler
from ..util.random_x_li_track import get_random_x_li_track

def fetch_posts(session, search_query, csrf, start_page, pagination_token):

    # if start_page == "0":
        # print("came here")
    start_index = 0
    aggregrated_data = []
    max_index = 50  # Loop until start_index reaches 60

    while start_index <= max_index:
        # Define the URL with the updated start_index
        url = f"https://www.linkedin.com/voyager/api/graphql?variables=(start:{start_index},origin:SWITCH_SEARCH_VERTICAL,query:(keywords:{search_query},flagshipSearchIntent:SEARCH_SRP,queryParameters:List((key:resultType,value:List(CONTENT))),includeFiltersInResponse:false),count:30)&queryId=voyagerSearchDashClusters.7e323a993aaa11dfaed2429df595a7cb"
        
        # Set the headers (X-Li-Track generated by get_random_x_li_track())
        headers = {
            'accept': 'application/vnd.linkedin.normalized+json+2.1',
            'accept-language': 'en-GB,en-IN;q=0.9,en-US;q=0.8,en;q=0.7,bn;q=0.6',
            'csrf-token': csrf.replace('"', ''),
            'sec-fetch-mode': 'cors',
            'sec-fetch-site': 'same-origin',
            'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',
            'Host': 'www.linkedin.com',
            'Sec-Ch-Ua': '"Not;A=Brand";v="24", "Chromium";v="128"',
            'X-Li-Lang': 'en_US',
            'Sec-Ch-Ua-Mobile': '?0',
            'Accept': 'application/vnd.linkedin.normalized+json+2.1',
            'X-Li-Track': get_random_x_li_track(),
            'X-Restli-Protocol-Version': '2.0.0',
            'X-Li-Pem-Metadata': 'Voyager - Content SRP=search-results',
            'Sec-Ch-Ua-Platform': '"Linux"',
            'Sec-Fetch-Dest': 'empty',
            'Accept-Encoding': 'gzip, deflate, br',
            'Priority': 'u=1, i',
        }

        # Send the request
        response = session.get(url, headers=headers)

        # Process the response using data_filler
        scraper_result = data_filler(response_text=response.text)

        # Check if scraper_result is not empty
        if scraper_result:
            # Append each object from scraper_result to aggregrated_data
            aggregrated_data.extend(scraper_result)

        # Increase start_index by 3 for the next loop
        start_index += 3

    sorted_data = sorted(
    aggregrated_data, 
    key=lambda x: x.get('num_likes', 0) + x.get('num_comments', 0) + x.get('num_shares', 0), 
    reverse=True
    )

    return sorted_data



def driver_function(data):
    search_query = data.query_string
    # cookie = cookie
    # print(cookie)
    # csrf = data.csrf
    search_query = search_query.replace(" ", "%")

    session, csrf = fetch_random_session()
    return fetch_posts(session, search_query, csrf, '0' , "")